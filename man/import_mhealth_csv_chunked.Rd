% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/import_data.R
\name{import_mhealth_csv_chunked}
\alias{import_mhealth_csv_chunked}
\title{Import large raw multi-channel accelerometer data stored in mHealth Specification
in chunks.}
\usage{
import_mhealth_csv_chunked(filepath, chunk_samples = 180000)
}
\arguments{
\item{filepath}{string. The filepath of the input data.}

\item{chunk_samples}{number. The number of samples in each chunk. Default is
180000, which is half hour data for 100 Hz sampling rate.}
}
\value{
list. The list contains three items. The first item is a generator
  function that each time it is called, it will
  return a list of \code{list(before_df, df, after_df)}. These are
  data.frames of imported chunks, ordered in time that can be loaded with
  the \code{\link{mims_unit}} function directly. The second item is a
  \code{has_more_chunks} function used to check if all chunks are loaded.
  If it returns \code{FALSE}, it means the loading has ended. The third item is a
  \code{close_connection} function which you can call at any moment to close the
  file loading.
}
\description{
\code{import_mhealth_csv_chunked} imports the raw multi-channel accelerometer
  data stored in mHealth Specification in chunks.
}
\section{How is it used in MIMS-unit algorithm?}{
 This function is a File IO
  function that is used to import data stored in mHealth Specification during
  algorithm validation.
}

\examples{
  # Use the mhealth csv file shipped with the package
  filepath = system.file('extdata', 'mhealth.csv', package='MIMSunit')

  # Load chunks every 25000 samples
  results = import_mhealth_csv_chunked(filepath, chunk_samples=25000)
  next_chunk = results[[1]]
  has_more_chunk = results[[2]]
  close_connection = results[[3]]
  # Call next chunk at least once before call other functions
  chunks = next_chunk()
  before_df = chunks[[1]]
  df = chunks[[2]]
  after_df = chunks[[3]]
  print('chunk 1')
  print(paste("before df:", before_df[1, 1], '-', before_df[nrow(before_df),1]))
  print(paste("df:", df[1, 1], '-', df[nrow(df),1]))
  print(paste("after df:", after_df[1, 1], '-', after_df[nrow(after_df),1]))
  # Check data as chunks, you can see chunks are shifted at each iteration.
  # The before_df in the next iteration will be df in the current iteration.
  n = 2
  while (has_more_chunk()) {
    chunks = next_chunk()
    before_df = chunks[[1]]
    df = chunks[[2]]
    after_df = chunks[[3]]
    print(paste('chunk', n))
    print(paste("before df:", before_df[1, 1], '-', before_df[nrow(before_df),1]))
    print(paste("df:", df[1, 1], '-', df[nrow(df),1]))
    print(paste("after df:", after_df[1, 1], '-', after_df[nrow(after_df),1]))
    n = n + 1
  }

  # Close connection after reading all the data
  close_connection()
}
\seealso{
Other File I/O functions: 
\code{\link{export_to_actilife}()},
\code{\link{import_actigraph_count_csv}()},
\code{\link{import_actigraph_csv_chunked}()},
\code{\link{import_actigraph_csv}()},
\code{\link{import_actigraph_meta}()},
\code{\link{import_activpal3_csv}()},
\code{\link{import_enmo_csv}()},
\code{\link{import_mhealth_csv}()}
}
\concept{File I/O functions}
